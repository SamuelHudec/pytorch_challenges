{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "import torch.nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.1969e-01, 2.0204e-01, 7.4227e-02, 4.8288e-01, 2.5578e-01, 9.8200e-01,\n         8.1767e-01, 2.4750e-01, 3.2467e-02, 4.4457e-01],\n        [8.2134e-01, 5.6919e-01, 1.6790e-01, 2.2054e-01, 8.3967e-01, 8.2551e-01,\n         5.3072e-01, 9.4100e-01, 4.6185e-01, 3.1954e-01],\n        [4.1773e-01, 7.4487e-01, 1.6388e-01, 2.4693e-01, 3.3744e-01, 3.7711e-01,\n         2.4320e-01, 7.4618e-01, 1.0891e-01, 8.1969e-02],\n        [8.6818e-01, 2.8101e-01, 1.5458e-01, 7.6317e-02, 2.3300e-01, 9.5962e-01,\n         5.7520e-01, 2.9543e-01, 3.4179e-01, 3.5040e-01],\n        [2.9278e-01, 4.2774e-01, 1.5241e-01, 6.2160e-01, 6.5064e-01, 9.2628e-02,\n         7.3330e-01, 6.3998e-01, 1.7768e-01, 3.4348e-01],\n        [3.6094e-01, 7.0825e-01, 8.8259e-01, 2.6447e-01, 5.5409e-01, 1.5825e-01,\n         5.0743e-01, 5.8728e-02, 4.1888e-01, 6.7353e-01],\n        [9.2190e-01, 6.7815e-01, 2.3121e-01, 9.2773e-01, 7.1300e-01, 8.7143e-01,\n         1.0195e-03, 8.1593e-02, 6.5719e-01, 4.1592e-01],\n        [9.0431e-01, 2.1170e-01, 9.7035e-01, 9.0812e-01, 1.0382e-01, 3.9990e-01,\n         1.7215e-01, 9.1596e-01, 6.0810e-01, 5.3265e-01],\n        [1.0495e-01, 5.7028e-01, 7.1527e-02, 1.0603e-01, 4.9309e-02, 9.9696e-01,\n         7.3884e-01, 1.0254e-01, 2.0505e-01, 7.9390e-01],\n        [7.4817e-01, 9.5903e-01, 3.0986e-02, 1.3864e-01, 3.5828e-01, 8.0312e-01,\n         3.0651e-01, 4.0875e-01, 3.0269e-01, 7.5456e-02],\n        [4.6177e-01, 2.1845e-01, 3.9936e-01, 2.7099e-01, 8.4448e-01, 1.8964e-01,\n         6.3836e-01, 4.8682e-01, 9.8510e-01, 3.3004e-01],\n        [5.7941e-01, 1.2079e-01, 5.7140e-01, 8.7632e-01, 5.9035e-01, 8.1857e-01,\n         7.0591e-01, 4.1898e-01, 1.6857e-01, 6.9810e-01],\n        [4.7225e-01, 9.8656e-01, 2.8329e-01, 5.8955e-04, 2.2674e-01, 3.8651e-01,\n         5.6102e-01, 4.8204e-01, 8.7735e-01, 1.0199e-01],\n        [5.6257e-01, 8.9750e-01, 4.1064e-01, 7.7816e-01, 2.6607e-01, 3.7213e-01,\n         6.0982e-01, 3.3236e-01, 3.6598e-01, 1.7685e-02],\n        [6.1142e-02, 8.0372e-01, 9.2501e-01, 6.4451e-01, 9.7819e-01, 6.2466e-01,\n         1.3441e-01, 4.0617e-01, 7.6053e-01, 7.9102e-01],\n        [4.3358e-01, 7.7450e-01, 7.8643e-01, 2.4153e-01, 2.6693e-01, 6.2193e-01,\n         2.0400e-01, 4.6301e-01, 2.1154e-01, 5.8454e-01],\n        [2.9190e-01, 3.4594e-01, 1.3717e-02, 2.1847e-01, 4.0577e-01, 8.0343e-01,\n         1.3392e-01, 9.6320e-01, 8.8221e-01, 9.6316e-01],\n        [5.2678e-01, 3.2970e-01, 7.2720e-01, 1.2544e-01, 1.5382e-01, 1.6610e-01,\n         5.0664e-01, 5.1333e-01, 7.3971e-01, 6.8366e-01],\n        [2.7552e-01, 4.4974e-01, 2.8971e-01, 4.3308e-01, 4.5860e-01, 2.3079e-02,\n         4.9649e-01, 4.7727e-01, 3.3756e-01, 3.6571e-01],\n        [5.1434e-01, 8.5495e-01, 8.0741e-01, 2.9228e-01, 5.6865e-01, 4.8968e-02,\n         8.6396e-01, 1.2694e-02, 6.1221e-01, 8.8016e-01],\n        [8.9256e-02, 4.9562e-01, 9.1974e-01, 4.3773e-01, 2.0448e-01, 6.1052e-01,\n         4.6787e-01, 1.4525e-01, 1.4756e-01, 7.4599e-01],\n        [7.4482e-01, 5.6768e-01, 5.4518e-01, 6.9199e-01, 9.3230e-01, 3.7309e-01,\n         9.0012e-01, 8.7218e-01, 6.6377e-01, 3.6990e-01],\n        [8.5012e-01, 1.0096e-01, 3.7126e-01, 7.5939e-01, 5.2664e-02, 1.8955e-01,\n         8.7561e-01, 1.3961e-01, 1.2762e-01, 5.7948e-01],\n        [2.8615e-01, 7.4398e-01, 6.8376e-01, 6.3184e-01, 3.7261e-01, 4.5797e-01,\n         7.3252e-01, 6.0195e-01, 1.8678e-01, 2.9049e-02],\n        [5.1866e-01, 8.9204e-01, 7.4767e-01, 8.4444e-01, 1.0759e-02, 3.5113e-01,\n         9.1219e-01, 2.4621e-01, 5.3609e-01, 9.6811e-01],\n        [1.0862e-01, 8.3735e-01, 6.0116e-02, 5.1509e-01, 2.5414e-01, 5.9397e-01,\n         1.9734e-01, 1.9094e-01, 7.3524e-01, 3.9658e-01],\n        [6.6040e-01, 2.4960e-01, 4.9694e-01, 1.3805e-01, 3.0890e-01, 2.7010e-01,\n         3.7879e-01, 5.0115e-01, 3.1458e-01, 8.7203e-01],\n        [5.8670e-01, 4.5332e-01, 3.8660e-01, 7.2399e-01, 5.7034e-01, 7.6501e-01,\n         8.7833e-01, 4.7773e-01, 3.9225e-02, 5.5488e-01],\n        [2.4051e-01, 6.2343e-01, 7.1862e-01, 4.1206e-01, 4.1189e-01, 2.8520e-01,\n         3.0240e-01, 4.6942e-01, 8.2786e-01, 3.0269e-01],\n        [4.1629e-01, 2.8073e-01, 3.8896e-01, 6.3698e-01, 5.2060e-01, 9.4830e-01,\n         8.3017e-01, 3.2693e-01, 9.1288e-01, 8.1057e-01],\n        [9.5980e-01, 7.6721e-01, 8.5589e-01, 6.1109e-01, 3.0338e-01, 7.9454e-01,\n         6.6997e-01, 5.8302e-01, 9.3163e-01, 4.7208e-01],\n        [3.7852e-01, 1.6145e-01, 2.2169e-01, 5.5647e-01, 6.7145e-02, 9.6146e-01,\n         5.1718e-01, 3.6071e-01, 8.8116e-01, 9.8161e-01],\n        [7.9868e-01, 6.2947e-01, 4.4177e-01, 6.7216e-01, 7.0591e-01, 2.3408e-01,\n         4.2721e-01, 3.4348e-02, 7.2193e-01, 8.9423e-01],\n        [5.0104e-01, 1.8102e-01, 4.8005e-01, 9.3199e-01, 6.3246e-01, 8.3508e-01,\n         8.3072e-02, 5.7193e-01, 9.1719e-01, 9.6208e-01],\n        [3.5655e-01, 7.9747e-01, 5.4269e-01, 2.2403e-01, 4.8699e-01, 4.1390e-01,\n         3.6426e-01, 7.5282e-01, 7.2694e-01, 5.9057e-01],\n        [1.7003e-01, 6.4103e-01, 1.5441e-02, 7.3382e-01, 1.3775e-01, 4.4393e-01,\n         2.9697e-03, 6.8183e-01, 1.3241e-01, 4.5952e-02],\n        [9.5483e-01, 3.6596e-01, 5.1038e-01, 8.3702e-01, 1.4777e-01, 2.4333e-01,\n         4.9804e-01, 4.6263e-01, 9.4374e-01, 6.4546e-01],\n        [1.6298e-01, 4.3950e-01, 2.7181e-01, 1.5422e-01, 7.9519e-01, 1.0807e-01,\n         4.7445e-01, 1.9104e-01, 7.3779e-01, 6.5440e-01],\n        [8.2931e-01, 3.7505e-01, 9.5790e-01, 3.9781e-01, 8.0692e-01, 9.0679e-01,\n         6.7482e-01, 8.8562e-01, 2.3781e-01, 3.9478e-01],\n        [8.1261e-01, 3.9253e-01, 3.2210e-02, 5.7822e-02, 4.2466e-01, 7.3581e-01,\n         4.3862e-01, 2.5117e-01, 7.7550e-01, 7.4049e-01],\n        [1.5239e-01, 1.5771e-02, 8.3260e-01, 1.0318e-01, 1.2629e-01, 6.6984e-01,\n         9.1740e-01, 3.4229e-01, 3.2358e-01, 5.8116e-01],\n        [1.5178e-01, 9.7535e-01, 1.5385e-01, 1.4691e-01, 7.2027e-01, 9.1960e-01,\n         6.0977e-01, 4.1641e-01, 4.8338e-01, 1.1316e-02],\n        [4.8494e-01, 5.9964e-01, 1.4462e-01, 3.6853e-02, 7.3809e-01, 1.7387e-02,\n         9.4363e-01, 6.5183e-01, 6.4923e-01, 9.3349e-01],\n        [4.3692e-01, 7.5024e-01, 4.3227e-01, 4.2426e-01, 5.5071e-01, 4.4188e-01,\n         7.9011e-01, 9.8544e-01, 3.9344e-02, 6.0164e-01],\n        [1.9518e-01, 7.1080e-01, 8.6775e-01, 4.1172e-01, 5.1026e-01, 8.2067e-01,\n         3.1931e-01, 4.2759e-02, 7.1001e-01, 1.3318e-01],\n        [8.0791e-02, 5.9938e-01, 7.0890e-01, 3.4154e-01, 4.6423e-01, 3.0321e-01,\n         8.2672e-01, 7.9427e-01, 2.9879e-01, 8.5369e-01],\n        [6.5767e-02, 2.7445e-01, 1.6876e-01, 1.2799e-01, 9.9437e-01, 2.6476e-01,\n         1.0287e-02, 4.2104e-02, 7.5469e-01, 1.9948e-01],\n        [9.2184e-01, 8.0871e-01, 3.0845e-01, 8.5849e-01, 6.2597e-01, 2.8782e-02,\n         1.2499e-01, 2.3393e-01, 3.6157e-01, 4.4098e-01],\n        [2.4764e-01, 9.6731e-01, 7.5401e-01, 8.0596e-01, 1.1921e-01, 5.7962e-01,\n         7.4380e-01, 7.7889e-01, 8.0962e-01, 5.9441e-01],\n        [1.2315e-01, 8.6198e-01, 6.3458e-01, 3.5605e-01, 6.0486e-01, 2.2619e-01,\n         7.2682e-01, 9.7052e-01, 9.2330e-01, 6.7223e-01]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(50, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "titles = pd.read_csv(f\"data/titles.csv\")\n",
    "titles_dict = dict(zip(titles.asin, titles.title))\n",
    "graph_dict = np.load(f\"data/graph_dict.npy\", allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgraph_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "graph_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([graph_dict.item().get(\"dst\"),graph_dict.item().get(\"src\")])\n",
    "set_edge_index = set(torch.cat([edge_index[0],edge_index[1]]).numpy().tolist())\n",
    "vocab = dict(zip(graph_dict.item().get(\"vocab_v\"), graph_dict.item().get(\"vocab_k\")))\n",
    "title_df = []\n",
    "for i in set_edge_index:\n",
    "    title_df.append(vocab[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'B011TPNIOO'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(title_df, columns=[\"asin\"]).merge(titles,on=\"asin\").fillna(\"error\")\n",
    "new_vocab = dict(zip(set_edge_index, np.arange(len(set_edge_index))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{786435: 0,\n 524291: 1,\n 262151: 2,\n 524296: 3,\n 786441: 4,\n 262155: 5,\n 262158: 6,\n 786447: 7,\n 786446: 8,\n 524311: 9,\n 25: 10,\n 26: 11,\n 786459: 12,\n 30: 13,\n 47: 14,\n 524339: 15,\n 786488: 16,\n 786489: 17,\n 524345: 18,\n 524346: 19,\n 61: 20,\n 69: 21,\n 70: 22,\n 524363: 23,\n 83: 24,\n 786519: 25,\n 786520: 26,\n 524384: 27,\n 524385: 28,\n 786530: 29,\n 98: 30,\n 786532: 31,\n 786534: 32,\n 103: 33,\n 110: 34,\n 786543: 35,\n 113: 36,\n 114: 37,\n 115: 38,\n 117: 39,\n 786549: 40,\n 119: 41,\n 104230: 42,\n 524411: 43,\n 262274: 44,\n 786571: 45,\n 524427: 46,\n 786572: 47,\n 524430: 48,\n 524433: 49,\n 146: 50,\n 153: 51,\n 364753: 52,\n 786590: 53,\n 786591: 54,\n 524449: 55,\n 524454: 56,\n 786600: 57,\n 786601: 58,\n 786602: 59,\n 786603: 60,\n 170: 61,\n 786605: 62,\n 524461: 63,\n 184: 64,\n 185: 65,\n 786618: 66,\n 524475: 67,\n 786622: 68,\n 786623: 69,\n 262338: 70,\n 479338: 71,\n 524484: 72,\n 524485: 73,\n 197: 74,\n 524487: 75,\n 524488: 76,\n 524486: 77,\n 202: 78,\n 524491: 79,\n 524492: 80,\n 786629: 81,\n 786635: 82,\n 207: 83,\n 208: 84,\n 52145: 85,\n 524500: 86,\n 786644: 87,\n 52146: 88,\n 524505: 89,\n 262362: 90,\n 524504: 91,\n 479339: 92,\n 786649: 93,\n 786654: 94,\n 235: 95,\n 236: 96,\n 238: 97,\n 524526: 98,\n 786678: 99,\n 264: 100,\n 265: 101,\n 786698: 102,\n 786700: 103,\n 786701: 104,\n 786702: 105,\n 524559: 106,\n 786705: 107,\n 786711: 108,\n 283: 109,\n 786718: 110,\n 786719: 111,\n 786720: 112,\n 786721: 113,\n 524579: 114,\n 786725: 115,\n 299: 116,\n 786731: 117,\n 300: 118,\n 524589: 119,\n 309: 120,\n 786743: 121,\n 318: 122,\n 786755: 123,\n 323: 124,\n 786759: 125,\n 330: 126,\n 524619: 127,\n 786762: 128,\n 524621: 129,\n 786764: 130,\n 524623: 131,\n 524624: 132,\n 786766: 133,\n 786775: 134,\n 786776: 135,\n 786777: 136,\n 524637: 137,\n 352: 138,\n 354: 139,\n 356: 140,\n 786792: 141,\n 262505: 142,\n 524650: 143,\n 262506: 144,\n 262508: 145,\n 367: 146,\n 524655: 147,\n 369: 148,\n 524660: 149,\n 786804: 150,\n 786815: 151,\n 384: 152,\n 385: 153,\n 386: 154,\n 387: 155,\n 524674: 156,\n 786817: 157,\n 262536: 158,\n 262539: 159,\n 398: 160,\n 262542: 161,\n 262545: 162,\n 524689: 163,\n 403: 164,\n 524693: 165,\n 786838: 166,\n 407: 167,\n 524695: 168,\n 262550: 169,\n 262551: 170,\n 412: 171,\n 413: 172,\n 414: 173,\n 786848: 174,\n 262562: 175,\n 421: 176,\n 262565: 177,\n 262566: 178,\n 426: 179,\n 427: 180,\n 262573: 181,\n 786863: 182,\n 432: 183,\n 786864: 184,\n 786865: 185,\n 524722: 186,\n 786866: 187,\n 786870: 188,\n 786875: 189,\n 444: 190,\n 448: 191,\n 450: 192,\n 451: 193,\n 786885: 194,\n 453: 195,\n 786888: 196,\n 459: 197,\n 262605: 198,\n 524750: 199,\n 786896: 200,\n 467: 201,\n 262611: 202,\n 468: 203,\n 471: 204,\n 472: 205,\n 262619: 206,\n 475: 207,\n 477: 208,\n 262622: 209,\n 479: 210,\n 524776: 211,\n 524777: 212,\n 524778: 213,\n 524781: 214,\n 494: 215,\n 498: 216,\n 499: 217,\n 524791: 218,\n 503: 219,\n 506: 220,\n 507: 221,\n 262652: 222,\n 262650: 223,\n 511: 224,\n 524808: 225,\n 524810: 226,\n 524812: 227,\n 524813: 228,\n 524815: 229,\n 531: 230,\n 537: 231,\n 538: 232,\n 262682: 233,\n 540: 234,\n 545: 235,\n 524833: 236,\n 786979: 237,\n 524837: 238,\n 551: 239,\n 524839: 240,\n 786984: 241,\n 786986: 242,\n 524846: 243,\n 559: 244,\n 262704: 245,\n 524849: 246,\n 558: 247,\n 524851: 248,\n 564: 249,\n 262708: 250,\n 566: 251,\n 786999: 252,\n 787000: 253,\n 524857: 254,\n 262714: 255,\n 524859: 256,\n 570: 257,\n 262717: 258,\n 574: 259,\n 787007: 260,\n 576: 261,\n 787008: 262,\n 571: 263,\n 262723: 264,\n 575: 265,\n 262725: 266,\n 524868: 267,\n 583: 268,\n 584: 269,\n 524874: 270,\n 787019: 271,\n 262733: 272,\n 787024: 273,\n 787028: 274,\n 787030: 275,\n 787036: 276,\n 524894: 277,\n 524896: 278,\n 787041: 279,\n 262756: 280,\n 613: 281,\n 618: 282,\n 787055: 283,\n 524917: 284,\n 787061: 285,\n 262777: 286,\n 787067: 287,\n 524925: 288,\n 262781: 289,\n 524926: 290,\n 262789: 291,\n 787078: 292,\n 524933: 293,\n 787080: 294,\n 262795: 295,\n 524939: 296,\n 787085: 297,\n 654: 298,\n 651: 299,\n 524941: 300,\n 658: 301,\n 524947: 302,\n 524948: 303,\n 524950: 304,\n 262807: 305,\n 262809: 306,\n 262810: 307,\n 524953: 308,\n 262813: 309,\n 671: 310,\n 262815: 311,\n 262818: 312,\n 524963: 313,\n 676: 314,\n 675: 315,\n 686: 316,\n 787119: 317,\n 262835: 318,\n 524980: 319,\n 694: 320,\n 524983: 321,\n 787130: 322,\n 262845: 323,\n 702: 324,\n 262853: 325,\n 787146: 326,\n 787149: 327,\n 719: 328,\n 720: 329,\n 722: 330,\n 787157: 331,\n 787158: 332,\n 262871: 333,\n 525018: 334,\n 787162: 335,\n 262876: 336,\n 938002: 337,\n 525022: 338,\n 525024: 339,\n 787169: 340,\n 747: 341,\n 752: 342,\n 525042: 343,\n 755: 344,\n 758: 345,\n 262903: 346,\n 262907: 347,\n 765: 348,\n 262909: 349,\n 262910: 350,\n 262912: 351,\n 769: 352,\n 525059: 353,\n 787204: 354,\n 773: 355,\n 777: 356,\n 787211: 357,\n 787214: 358,\n 525071: 359,\n 784: 360,\n 787218: 361,\n 525076: 362,\n 793: 363,\n 795: 364,\n 525086: 365,\n 787234: 366,\n 787237: 367,\n 811: 368,\n 525100: 369,\n 787247: 370,\n 525105: 371,\n 802390: 372,\n 825: 373,\n 525114: 374,\n 262970: 375,\n 262973: 376,\n 262974: 377,\n 831: 378,\n 262976: 379,\n 787262: 380,\n 787271: 381,\n 787272: 382,\n 787273: 383,\n 262990: 384,\n 787279: 385,\n 525137: 386,\n 262994: 387,\n 851: 388,\n 262996: 389,\n 262997: 390,\n 262995: 391,\n 525145: 392,\n 859: 393,\n 787291: 394,\n 862: 395,\n 263007: 396,\n 787296: 397,\n 263009: 398,\n 866: 399,\n 868: 400,\n 869: 401,\n 885926: 402,\n 871: 403,\n 872: 404,\n 787305: 405,\n 263018: 406,\n 525157: 407,\n 525164: 408,\n 787304: 409,\n 787310: 410,\n 787311: 411,\n 787313: 412,\n 525171: 413,\n 787317: 414,\n 525174: 415,\n 887: 416,\n 525176: 417,\n 525177: 418,\n 525178: 419,\n 525179: 420,\n 787328: 421,\n 787329: 422,\n 787330: 423,\n 787331: 424,\n 898: 425,\n 263041: 426,\n 787334: 427,\n 787335: 428,\n 787339: 429,\n 787340: 430,\n 911: 431,\n 787343: 432,\n 864915: 433,\n 525207: 434,\n 525211: 435,\n 787357: 436,\n 525219: 437,\n 936: 438,\n 787368: 439,\n 939: 440,\n 525227: 441,\n 943: 442,\n 525237: 443,\n 525238: 444,\n 955: 445,\n 958: 446,\n 263104: 447,\n 961: 448,\n 787393: 449,\n 525252: 450,\n 525254: 451,\n 525257: 452,\n 525258: 453,\n 971: 454,\n 972: 455,\n 525261: 456,\n 525274: 457,\n 787419: 458,\n 525276: 459,\n 988: 460,\n 525277: 461,\n 992: 462,\n 787425: 463,\n 995: 464,\n 996: 465,\n 997: 466,\n 525287: 467,\n 885952: 468,\n 1004: 469,\n 787438: 470,\n 52304: 471,\n 525300: 472,\n 263158: 473,\n 1017: 474,\n 525307: 475,\n 263170: 476,\n 1029: 477,\n 833855: 478,\n 1036: 479,\n 1037: 480,\n 525324: 481,\n 1039: 482,\n 1040: 483,\n 525327: 484,\n 1042: 485,\n 1043: 486,\n 525331: 487,\n 1045: 488,\n 787478: 489,\n 1046: 490,\n 1048: 491,\n 263189: 492,\n 525329: 493,\n 885962: 494,\n 1056: 495,\n 1057: 496,\n 1058: 497,\n 263201: 498,\n 787489: 499,\n 1061: 500,\n 263202: 501,\n 263206: 502,\n 263208: 503,\n 263204: 504,\n 263210: 505,\n 787494: 506,\n 787499: 507,\n 525357: 508,\n 1069: 509,\n 525358: 510,\n 263214: 511,\n 1066: 512,\n 1074: 513,\n 263212: 514,\n 263219: 515,\n 1077: 516,\n 525365: 517,\n 263224: 518,\n 787512: 519,\n 525369: 520,\n 1083: 521,\n 1085: 522,\n 263229: 523,\n 263230: 524,\n 1086: 525,\n 263233: 526,\n 525375: 527,\n 263235: 528,\n 787523: 529,\n 787518: 530,\n 1094: 531,\n 1095: 532,\n 263239: 533,\n 525386: 534,\n 263244: 535,\n 525388: 536,\n 1100: 537,\n 1102: 538,\n 1104: 539,\n 525393: 540,\n 1105: 541,\n 1107: 542,\n 263252: 543,\n 52323: 544,\n 1110: 545,\n 525399: 546,\n 1111: 547,\n 263257: 548,\n 263258: 549,\n 1114: 550,\n 1116: 551,\n 1117: 552,\n 1118: 553,\n 1115: 554,\n 1120: 555,\n 263269: 556,\n 1126: 557,\n 1128: 558,\n 1129: 559,\n 263274: 560,\n 263272: 561,\n 1132: 562,\n 1133: 563,\n 525421: 564,\n 263277: 565,\n 1136: 566,\n 525425: 567,\n 263281: 568,\n 1139: 569,\n 1140: 570,\n 263284: 571,\n 1135: 572,\n 1143: 573,\n 263287: 574,\n 263288: 575,\n 263289: 576,\n 263291: 577,\n 525435: 578,\n 263293: 579,\n 1150: 580,\n 1151: 581,\n 1147: 582,\n 263297: 583,\n 263298: 584,\n 1155: 585,\n 263300: 586,\n 787582: 587,\n 263302: 588,\n 263303: 589,\n 1160: 590,\n 263304: 591,\n 1162: 592,\n 1163: 593,\n 1164: 594,\n 263308: 595,\n 787598: 596,\n 525455: 597,\n 263312: 598,\n 263313: 599,\n 787602: 600,\n 1171: 601,\n 263315: 602,\n 263317: 603,\n 263318: 604,\n 787603: 605,\n 263320: 606,\n 1174: 607,\n 1178: 608,\n 263322: 609,\n 263324: 610,\n 263325: 611,\n 1182: 612,\n 1183: 613,\n 1177: 614,\n 263329: 615,\n 1186: 616,\n 1187: 617,\n 1188: 618,\n 1189: 619,\n 263333: 620,\n 263335: 621,\n 1192: 622,\n 263337: 623,\n 1193: 624,\n 1194: 625,\n 263340: 626,\n 263341: 627,\n 263342: 628,\n 1197: 629,\n 263343: 630,\n 263345: 631,\n 263346: 632,\n 787633: 633,\n 1204: 634,\n 263348: 635,\n 787638: 636,\n 525488: 637,\n 1208: 638,\n 263353: 639,\n 525498: 640,\n 1212: 641,\n 263357: 642,\n 1215: 643,\n 1216: 644,\n 263361: 645,\n 263362: 646,\n 263363: 647,\n 1219: 648,\n 1221: 649,\n 263366: 650,\n 263367: 651,\n 1224: 652,\n 525513: 653,\n 1226: 654,\n 263370: 655,\n 263372: 656,\n 263371: 657,\n 525511: 658,\n 787663: 659,\n 1231: 660,\n 263375: 661,\n 263376: 662,\n 1235: 663,\n 1236: 664,\n 263379: 665,\n 263382: 666,\n 263377: 667,\n 525522: 668,\n 525525: 669,\n 1242: 670,\n 787669: 671,\n 263388: 672,\n 263380: 673,\n 263390: 674,\n 525530: 675,\n 787676: 676,\n 263391: 677,\n 525538: 678,\n 263395: 679,\n 525540: 680,\n 1250: 681,\n 1254: 682,\n 263399: 683,\n 1256: 684,\n 263401: 685,\n 364972: 686,\n 263403: 687,\n 1262: 688,\n 263407: 689,\n 787695: 690,\n 1263: 691,\n 263408: 692,\n 1267: 693,\n 1268: 694,\n 1269: 695,\n 525558: 696,\n 525559: 697,\n 1272: 698,\n 263410: 699,\n 525556: 700,\n 1271: 701,\n 1275: 702,\n 263418: 703,\n 787710: 704,\n 1279: 705,\n 525567: 706,\n 1281: 707,\n 1282: 708,\n 1283: 709,\n 263428: 710,\n 525570: 711,\n 787718: 712,\n 263431: 713,\n 1288: 714,\n 263433: 715,\n 525577: 716,\n 263434: 717,\n 263435: 718,\n 1290: 719,\n 787723: 720,\n 1291: 721,\n 787726: 722,\n 263441: 723,\n 787730: 724,\n 1299: 725,\n 263444: 726,\n 263443: 727,\n 525590: 728,\n 787735: 729,\n 525591: 730,\n 263448: 731,\n 1306: 732,\n 263450: 733,\n 787738: 734,\n 787739: 735,\n 787741: 736,\n 787743: 737,\n 263455: 738,\n 52364: 739,\n 525602: 740,\n 787746: 741,\n 1316: 742,\n 787750: 743,\n 263463: 744,\n 525608: 745,\n 263465: 746,\n 787752: 747,\n 1323: 748,\n 263467: 749,\n 525612: 750,\n 787754: 751,\n 1327: 752,\n 263472: 753,\n 263471: 754,\n 1330: 755,\n 263475: 756,\n 263474: 757,\n 263476: 758,\n 263478: 759,\n 1334: 760,\n 1336: 761,\n 263480: 762,\n 263477: 763,\n 1339: 764,\n 263483: 765,\n 263485: 766,\n 787769: 767,\n 263487: 768,\n 263488: 769,\n 263489: 770,\n 263490: 771,\n 1343: 772,\n 1345: 773,\n 263493: 774,\n 263494: 775,\n 525639: 776,\n 263496: 777,\n 1353: 778,\n 263498: 779,\n 263499: 780,\n 263500: 781,\n 263501: 782,\n 263502: 783,\n 263497: 784,\n 1357: 785,\n 263505: 786,\n 1362: 787,\n 263503: 788,\n 525646: 789,\n 787791: 790,\n 525647: 791,\n 263511: 792,\n 1360: 793,\n 787801: 794,\n 1369: 795,\n 263515: 796,\n 263516: 797,\n 1372: 798,\n 1371: 799,\n 525662: 800,\n 263520: 801,\n 1376: 802,\n 1378: 803,\n 263523: 804,\n 787812: 805,\n 156583: 806,\n 1382: 807,\n 263527: 808,\n 263526: 809,\n 787815: 810,\n 263521: 811,\n 263522: 812,\n 263532: 813,\n 263529: 814,\n 364997: 815,\n 1391: 816,\n 525678: 817,\n 1393: 818,\n 525682: 819,\n 263539: 820,\n 1395: 821,\n 525684: 822,\n 1398: 823,\n 263542: 824,\n 525688: 825,\n 263545: 826,\n 1402: 827,\n 787834: 828,\n 263548: 829,\n 787837: 830,\n 263550: 831,\n 787839: 832,\n 525692: 833,\n 525696: 834,\n 1404: 835,\n 263555: 836,\n 525693: 837,\n 525699: 838,\n 1415: 839,\n 1416: 840,\n 787849: 841,\n 787847: 842,\n 1417: 843,\n 525708: 844,\n 263565: 845,\n 525710: 846,\n 525709: 847,\n 1425: 848,\n 1426: 849,\n 1427: 850,\n 1428: 851,\n 1429: 852,\n 1430: 853,\n 1431: 854,\n 1432: 855,\n 1433: 856,\n 1434: 857,\n 787865: 858,\n 525724: 859,\n 525725: 860,\n 1438: 861,\n 1440: 862,\n 525729: 863,\n 263584: 864,\n 525730: 865,\n 525728: 866,\n 525733: 867,\n 525735: 868,\n 1449: 869,\n 525737: 870,\n 525740: 871,\n 525742: 872,\n 263599: 873,\n 787888: 874,\n 1456: 875,\n 525746: 876,\n 525744: 877,\n 525747: 878,\n 1462: 879,\n 525752: 880,\n 1465: 881,\n 1466: 882,\n 263609: 883,\n 1468: 884,\n 787900: 885,\n 1472: 886,\n 787904: 887,\n 1476: 888,\n 1477: 889,\n 1478: 890,\n 1479: 891,\n 1483: 892,\n 787915: 893,\n 1485: 894,\n 1484: 895,\n 525775: 896,\n 263633: 897,\n 525779: 898,\n 1495: 899,\n 1496: 900,\n 1498: 901,\n 525788: 902,\n 1501: 903,\n 1505: 904,\n 1508: 905,\n 1514: 906,\n 263661: 907,\n 787950: 908,\n 787951: 909,\n 787952: 910,\n 1521: 911,\n 263668: 912,\n 263670: 913,\n 1530: 914,\n 365026: 915,\n 1533: 916,\n 525824: 917,\n 1539: 918,\n 525830: 919,\n 1545: 920,\n 1546: 921,\n 525834: 922,\n 1548: 923,\n 1549: 924,\n 525838: 925,\n 787983: 926,\n 1551: 927,\n 525835: 928,\n 1554: 929,\n 525837: 930,\n 525839: 931,\n 525840: 932,\n 1558: 933,\n 525841: 934,\n 1560: 935,\n 1561: 936,\n 525842: 937,\n 525843: 938,\n 525844: 939,\n 1565: 940,\n 525845: 941,\n 787999: 942,\n 525848: 943,\n 525851: 944,\n 525853: 945,\n 263715: 946,\n 1572: 947,\n 525854: 948,\n 525855: 949,\n 525861: 950,\n 788009: 951,\n 788021: 952,\n 788022: 953,\n 788024: 954,\n 1593: 955,\n 525883: 956,\n 1596: 957,\n 788029: 958,\n 263742: 959,\n 1600: 960,\n 1603: 961,\n 1604: 962,\n 1606: 963,\n 1607: 964,\n 1608: 965,\n 1610: 966,\n 1611: 967,\n 1613: 968,\n 1614: 969,\n 1617: 970,\n 525905: 971,\n 1620: 972,\n 788054: 973,\n 263767: 974,\n 525911: 975,\n 525910: 976,\n 525912: 977,\n 1623: 978,\n 788060: 979,\n 1630: 980,\n 1632: 981,\n 1635: 982,\n 1637: 983,\n 1638: 984,\n 788069: 985,\n 1640: 986,\n 1641: 987,\n 788071: 988,\n 1643: 989,\n 788073: 990,\n 1645: 991,\n 525934: 992,\n 1642: 993,\n 1648: 994,\n 263793: 995,\n 525938: 996,\n 263796: 997,\n 1654: 998,\n 525943: 999,\n ...}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fasttext' has no attribute 'util'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ft \u001B[38;5;241m=\u001B[39m \u001B[43mfasttext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutil\u001B[49m\u001B[38;5;241m.\u001B[39mdownload_model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m'\u001B[39m, if_exists\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# English\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#ft = fasttext.load_model(f'data/fasttext')\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'fasttext' has no attribute 'util'"
     ]
    }
   ],
   "source": [
    "ft = fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "#ft = fasttext.load_model(f'data/fasttext')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "x = [ft.get_sentence_vector(i) for i in titles.title.values]\n",
    "# x = torch.rand((len(set_),50))\n",
    "\n",
    "\n",
    "edge_index = torch.tensor([[new_vocab[i] for i in graph_dict.item().get(\"dst\")],\n",
    "                           [new_vocab[i] for i in graph_dict.item().get(\"src\")]])\n",
    "#data = Data(torch.tensor(x), edge_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch_geometric # torch_sparse, torch_scatter needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ju = torch_geometric.nn.GATConv(3,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.6349, 2.1630, 1.6182, 1.6838, 1.3377, 1.4920, 1.6256, 1.6339, 1.7371,\n         2.2183]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 10)\n",
    "torch.exp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def _GAT(emb: torch.tensor, edge: torch.tensor) -> torch.tensor:\n",
    "    # should add test on matrix positive semi-definite\n",
    "    emb_dim = emb.size(dim=0)\n",
    "    edge_dim = edge.size(dim=1)\n",
    "    e = torch.exp(torch.matmul(emb, torch.t(emb)))\n",
    "    att_mask = torch.zeros(emb_dim, emb_dim, dtype=torch.int)\n",
    "    edge = edge - 1\n",
    "    for i in range(edge_dim):\n",
    "        att_mask[edge[0, i], edge[1, i]] = 1\n",
    "        att_mask[edge[1, i], edge[0, i]] = 1\n",
    "    e_adj = e * att_mask\n",
    "    den = e_adj.sum(dim=1)\n",
    "    output = e.t()/den\n",
    "    return output.t()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.7690e+01, 1.0288e-02, 2.2624e-02, 8.3535e-01, 1.3173e-01],\n        [4.1806e-01, 7.3311e+00, 3.8382e-02, 3.5379e-01, 1.8977e-01],\n        [8.7385e-01, 3.6485e-02, 2.7855e+00, 4.5022e-01, 8.9665e-02],\n        [7.4864e-01, 7.8030e-03, 1.0446e-02, 5.3645e+01, 2.4356e-01],\n        [3.2091e-01, 1.1377e-02, 5.6552e-03, 6.6205e-01, 1.8216e+00]])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 50)\n",
    "edge_idx = torch.tensor([[1, 1, 1, 1, 3, 4, 2, 2, 5, 5], [3, 4, 5, 2, 2, 5, 4, 5, 3, 1]])\n",
    "_GAT(x, edge_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8766, 0.4007, 0.1633, 0.7260, 0.1738, 0.0155, 0.9866, 0.3804, 0.2972,\n         0.4922, 0.0159, 0.5795, 0.8394, 0.6456, 0.9783, 0.1004, 0.2158, 0.2108,\n         0.1336, 0.0184, 0.2577, 0.2061, 0.1826, 0.9161, 0.5521, 0.3995, 0.8508,\n         0.8500, 0.8470, 0.1157, 0.9594, 0.7116, 0.8570, 0.5860, 0.9802, 0.3832,\n         0.8145, 0.0058, 0.7193, 0.8290, 0.8195, 0.1707, 0.7694, 0.4258, 0.8122,\n         0.0460, 0.7492, 0.5962, 0.4674, 0.1421],\n        [0.3145, 0.6398, 0.6307, 0.1848, 0.0457, 0.5892, 0.1195, 0.3138, 0.4133,\n         0.7032, 0.0825, 0.2719, 0.5281, 0.0975, 0.2124, 0.5148, 0.6765, 0.7853,\n         0.0640, 0.6103, 0.7625, 0.4467, 0.0145, 0.2253, 0.7009, 0.3940, 0.5153,\n         0.8286, 0.3955, 0.0527, 0.0014, 0.2011, 0.5724, 0.0694, 0.1095, 0.0196,\n         0.1608, 0.7893, 0.8916, 0.3762, 0.7408, 0.0720, 0.9956, 0.7485, 0.2643,\n         0.9527, 0.2857, 0.5238, 0.3789, 0.3951],\n        [0.5331, 0.0227, 0.6842, 0.5282, 0.4295, 0.7264, 0.6918, 0.6725, 0.6564,\n         0.5504, 0.3741, 0.7943, 0.6556, 0.4560, 0.1325, 0.5116, 0.2216, 0.6740,\n         0.7045, 0.9053, 0.5834, 0.4880, 0.9531, 0.5322, 0.7856, 0.5656, 0.0060,\n         0.5440, 0.6292, 0.5230, 0.4082, 0.2320, 0.7593, 0.1565, 0.0815, 0.6884,\n         0.2836, 0.6923, 0.7482, 0.5379, 0.7010, 0.5157, 0.9288, 0.6278, 0.7400,\n         0.5818, 0.1365, 0.5906, 0.4520, 0.3726],\n        [0.3462, 0.1900, 0.4068, 0.5822, 0.2286, 0.8672, 0.6538, 0.5592, 0.1321,\n         0.5014, 0.6552, 0.7552, 0.8708, 0.5257, 0.7428, 0.4151, 0.8378, 0.6997,\n         0.6885, 0.6052, 0.4821, 0.4085, 0.4388, 0.5387, 0.7693, 0.8114, 0.8565,\n         0.9049, 0.5202, 0.0532, 0.7331, 0.3787, 0.3477, 0.7377, 0.6581, 0.4778,\n         0.7251, 0.9564, 0.9277, 0.6316, 0.3951, 0.3899, 0.7510, 0.1255, 0.6427,\n         0.7108, 0.2785, 0.6249, 0.3564, 0.6795],\n        [0.7690, 0.8678, 0.0134, 0.8214, 0.7510, 0.3190, 0.3774, 0.7834, 0.7651,\n         0.9055, 0.1952, 0.9558, 0.9354, 0.7302, 0.6796, 0.2808, 0.1258, 0.5758,\n         0.8789, 0.1276, 0.0686, 0.2647, 0.5211, 0.2628, 0.3767, 0.6884, 0.9263,\n         0.8086, 0.7002, 0.1515, 0.5003, 0.2067, 0.8651, 0.2281, 0.4589, 0.8643,\n         0.9268, 0.0479, 0.7893, 0.9170, 0.9650, 0.7273, 0.1145, 0.5610, 0.0306,\n         0.3543, 0.4425, 0.2381, 0.0101, 0.5350]])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0792, 0.6708, 0.1733, 0.4421, 0.4331])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.0792, 0.6708, 0.1733, 0.4421, 0.4331])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5)\n",
    "print(x)\n",
    "x.t()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0.25198773709528677"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.121/44.1331"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}